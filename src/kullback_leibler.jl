"""
    kullback_leibler(
        a::Distribution{Multivariate},
        b::Distribution{Multivariate}
    ) -> Float64

Calculate the Kullback-Leibler divergence between two gaussian distributions.

https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence#Multivariate_normal_distributions
"""
function kullback_leibler(a::MvNormal, b::MvNormal)
    @_dimcheck size(a) == size(b)
    @_dimcheck length(a) == length(b)

    # Pull out the covariance matrices
    Î£0 = cov(a)
    Î£1 = cov(b)

    # Make sure that the covariance is not singular
    @_dimcheck det(Î£0) != 0
    @_dimcheck det(Î£1) != 0

    # k is the Distribution Dimension
    k = length(a)

    # Pull out the means
    ğœ‡0 = mean(a)
    ğœ‡1 = mean(b)
    ğœ‡diff = ğœ‡1 .- ğœ‡0

    # ğœ‡diff' * (Î£1 \ ğœ‡diff) can be more efficiently computed using the Cholesky
    Z = cholesky(Î£1).L \ ğœ‡diff

    kl = 0.5 * (tr(Î£1 \ Î£0) + Z' * Z - k + log(det(Î£1) / det(Î£0)))

    return kl
end

obs_arrangement(::typeof(kullback_leibler)) = SingleObs()
const kl = kullback_leibler
